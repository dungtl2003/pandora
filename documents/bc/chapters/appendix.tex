% \newlist{myap}{enumerate}{5}
% \newcommand{\myapi}{\arabic{myapi}.}
% \newcommand{\myapii}{\myapi\arabic{myapii}.}
% \newcommand{\myapiii}{\myapii\arabic{myapiii}.}
% \newcommand{\myapiv}{\myapiii\arabic{myapiv}.}
% \newcommand{\myapv}{\myapiv\arabic{myapv}.}

% \setlist[myap,1]{
%     label = \fontsize{13}{0} Phụ lục \myapi,
%     leftmargin=2.5cm,
%     %rightmargin=10pt
% }
% \setlist[myap,2]{
%     label = \myapii
% }
% \setlist[myap,3]{
%     label = \myapiii
% }
% \setlist[myap,4]{
%     label = \myapiv
% }
% \setlist[myap,5]{
%     label = \myapv
% }




\chapter*{PHỤ LỤC}
\addcontentsline{toc}{chapter}{PHỤ LỤC}
\addtocontents{toc}{\protect\setcounter{tocdepth}{0}}
{
\setcounter{chapter}{1}
% \titleformat{\chapter}[block]{\centering}{\textbf{\MakeUppercase\chaptername\space\thechapter.\space}}{0pt}{\textbf}{}
\renewcommand{\thesection}{\arabic{section}}
\renewcommand{\thesubsection}{\thesection.\arabic{subsection}}
\renewcommand{\thesubsubsection}{\thesubsection.\arabic{subsubsection}}
\renewcommand{\theparagraph}{\thesubsubsection.\arabic{paragraph}}
\renewcommand{\thesubparagraph}{\theparagraph.\arabic{subparagraph}}
\titleformat{\section}[block]{}{\textbf{Phụ lục \thesection. }}{0pt}{\textbf}{}
\titleformat{\subsection}[block]{}{\textbf{\thesubsection. }}{0pt}{\textbf}{}
\titleformat{\subsubsection}[block]{}{\textbf{\thesubsubsection. }}{0pt}{\textbf}{}
\titleformat{\paragraph}[block]{}{\textbf{\theparagraph. }}{0pt}{\textbf}{}
\titleformat{\subparagraph}[block]{}{\textbf{\thesubparagraph. }}{0pt}{\textbf}{}


\section{Mã chương trình}
\subsection{Bộ phân tích từ vựng}
\subsubsection{Phân tích từ tố sơ cấp}
\begin{itemize}
  \item \label{ap1:simple_token}Từ tố sơ cấp. \textbf{(lexer::token::Token)}
  \begin{lstlisting}[]
    pub struct Token {
      pub kind: TokenKind,
      pub len: u32,
    }
  \end{lstlisting}
  \item \label{ap1:simple_token_kind}Các loại từ tố sơ cấp. \textbf{(lexer::token::TokenKind)}
  \begin{lstlisting}[]
    pub enum TokenKind {
      /* one char symbol */
      /// :
      Colon,
      /// ,
      Comma,
      /// .
      Dot,
      /// ;
      Semicolon,
      /// ?
      Question,
      /// (
      OpenParen,
      /// )
      CloseParen,
      /// {
      OpenBrace,
      /// }
      CloseBrace,
      /// [
      OpenBracket,
      /// ]
      CloseBracket,
      /// `!`
      Bang,
      /// `=`
      Eq,
      /// `>`
      Gt,
      /// `<`
      Lt,
      /// `~`
      Tilde,
      /// `+`
      Plus,
      /// `-`
      Minus,
      /// `*`
      Star,
      /// `/`
      Slash,
      /// `%`
      Percent,
      /// `^`
      Caret,
      /// `&`
      And,
      /// `|`
      Or,

      // Literal
      Literal(LiteralKind),

      // Identifier
      Ident,

      // Raw identifier
      RawIdent,

      // Comments
      LineComment {
          doc_style: Option<DocStyle>,
      },
      BlockComment {
          doc_style: Option<DocStyle>,
          terminated: bool,
      },

      Whitespace,

      // Unknown token's kind.
      Unknown,

      /// End of input.
      Eof,
    }
  \end{lstlisting}
  \item \label{ap1:simple_token_literal}Loại từ tố chuỗi ký tự. \textbf{(lexer::token::LiteralKind)}
  \begin{lstlisting}
    pub enum LiteralKind {
      /// `"abc"`, `"ab`, `"ab\"`, `"ab\""`.
      Str {
          terminated: bool,
      },
      /// `r#"abc"#`, `r###"ab"##c"###`, `r###"ab"######`, None means invalid.
      RawStr {
          n_hashes: Option<u8>,
      },
      /// `1_000`, `0b1101`, `0o657`, `0h1af9`.
      Int {
          base: Base,
          empty_int: bool,
      },
      Float {
          base: Base,
          empty_exponent: bool,
      },
      // Although kind can be Char but it can be many symbols (error). Ex: 'abc' -> error.
      /// `'a'`, `'\''`, `'\\'`, `'abc'`, `'ab`.
      Char {
          terminated: bool,
      },
    }
  \end{lstlisting}
  \item \label{ap1:simple_token_advance_token}Hàm \textit{advance\_token}. \textbf{(lexer::advance\_token)}
  \begin{lstlisting}
    pub fn advance_token(&mut self) -> Token {
      self.reset_bytes_eaten();

      let first_char = match self.eat() {
          Some(c) => c,
          None => return Token::new(TokenKind::Eof, 0),
      };

      let kind = match first_char {
          c if is_whitespace(c) => self.whitespace(),

          ':' => TokenKind::Colon,
          ',' => TokenKind::Comma,
          '.' => TokenKind::Dot,
          ';' => TokenKind::Semicolon,
          '?' => TokenKind::Question,
          '(' => TokenKind::OpenParen,
          ')' => TokenKind::CloseParen,
          '[' => TokenKind::OpenBracket,
          ']' => TokenKind::CloseBracket,
          '{' => TokenKind::OpenBrace,
          '}' => TokenKind::CloseBrace,
          '!' => TokenKind::Bang,
          '=' => TokenKind::Eq,
          '>' => TokenKind::Gt,
          '<' => TokenKind::Lt,
          '~' => TokenKind::Tilde,
          '+' => TokenKind::Plus,
          '-' => TokenKind::Minus,
          '*' => TokenKind::Star,
          '%' => TokenKind::Percent,
          '^' => TokenKind::Caret,
          '&' => TokenKind::And,
          '|' => TokenKind::Or,

          // Slash, comment or block comment.
          '/' => match self.first() {
              '/' => self.line_comment(),
              '*' => self.block_comment(),
              _ => TokenKind::Slash,
          },

          '0'..='9' => self.number(),

          // Raw identifier, Identifier, Raw double quote string
          'r' => match (self.first(), self.second()) {
              ('#', c1) if is_id_start(c1) => self.raw_identifier(),
              ('#', _) | ('"', _) => {
                  let res = self.raw_double_quote_string();
                  TokenKind::Literal(LiteralKind::RawStr { n_hashes: res.ok() })
              }
              _ => self.identifier(),
          },

          '\'' => self.single_quote_string(),
          '"' => self.double_quote_string(),

          c if is_id_start(c) => self.identifier(),

          _ => TokenKind::Unknown,
      };

      Token::new(kind, self.bytes_eaten())
    }
  \end{lstlisting}
\end{itemize}

\subsubsection{Phân tích từ tố thứ cấp}
\begin{itemize}
  \item \label{ap1:flex_token}Từ tố thứ cấp. \textbf{(ast::token::Token)}
  \begin{lstlisting}[]
    pub struct Token {
      pub kind: TokenKind,
      pub span: Span,
    }
  \end{lstlisting}
  \item \label{ap1:flex_token_span}Vị trí của từ tố thứ cấp.
  \item \label{ap1:flex_token_kind}Các loại từ tố thứ cấp.
\begin{lstlisting}
pub enum TokenKind {
    /* Expression-operator symbols. */
    /// `=`
    Eq,
    /// `<`
    Lt,
    /// `<=`
    Le,
    /// `==`
    EqEq,
    /// `!=`
    Ne,
    /// `>=`
    Ge,
    /// `>`
    Gt,
    /// `&&`
    AndAnd,
    /// `||`
    OrOr,
    /// `!`
    Not,
    /// `~`
    Tilde,
    BinOp(BinOpToken),
    BinOpEq(BinOpToken),
    
    /* Structural symbols */
    /// `.`
    Dot,
    /// `,`
    Comma,
    /// `;`
    Semicolon,
    /// `:`
    Colon,
    /// `::`
    PathSep,
    /// `->`
    RArrow,
    /// `?`
    Question,
    /// An opening delimiter (e.g., `{`).
    OpenDelim(Delimiter),
    /// A closing delimiter (e.g., `}`).
    CloseDelim(Delimiter),
    
    /* Literals */
    Literal(Lit),
    
    Ident(Symbol, IdentIsRaw),
    
    /// A doc comment token.
    /// `Symbol` is the data of doc's comment excluding its "quotes" (`///`, `/**`, etc)
    DocComment(CommentKind, Option<DocStyle>, Symbol),
    
    /// End Of File.
    Eof,
}
\end{lstlisting}
  \item \label{ap1:flex_token_bin_op}Loại từ tố phép toán học.
  \item \label{ap1:flex_token_delimiter}Loại từ tố ngoặc.
  \item \label{ap1:flex_token_literal}Loại từ tố chuỗi ký tự.
  \item \label{ap1:flex_token_identifier}Loại từ tố tên.
  \item \label{ap1:flex_token_doc_cmt}Loại từ tố chú thích tài liệu.
  \item \label{ap1:flex_token_next_token}Hàm \textit{next\_token}
\end{itemize}

\subsubsection{Phân tích cây từ tố}
\begin{itemize}
    \item \label{ap1:token_tree_lex_token_trees}Hàm \textit{lex\_token\_trees}
    \item 
\begin{lstlisting}
fn lex_token_trees(&mut self, is_delimited: bool) -> (TokenStream, PResult<()>) {
    // This can be the first token or open delim, can not glue.
    self.eat(false);

    let mut buf = Vec::new();
    loop {
        match self.token.kind {
            TokenKind::OpenDelim(delim) => match self.lex_token_tree_open_delim(delim) {
                Ok(val) => buf.push(val),
                Err(err) => return (TokenStream::new(buf), Err(err)),
            },
            TokenKind::CloseDelim(delim) => {
                if !is_delimited {
                    let err = PError::UnexpectedClosingDelimiter {
                        delimiter: delim,
                        span: self.token.span,
                    };
                    return (TokenStream::new(buf), Err(vec![err]));
                }
                return (TokenStream::new(buf), Ok(()));
            }
            TokenKind::Eof => {
                if is_delimited {
                    // This is weird but for display.
                    let span = Span::new(self.token.span.offset - 1, self.token.span.offset);
                    let err = PError::UnclosedDelimiter {
                        unclosed_delimiter_spans: self
                            .open_delims
                            .iter()
                            .map(|&(_, span)| span)
                            .collect(),
                        suggest_close_pos_span: Some(span),
                    };
                    return (TokenStream::new(buf), Err(vec![err]));
                }
                return (TokenStream::new(buf), Ok(()));
            }
            _ => {
                // Get the next normal token.
                // We will have the previous token, so we can try to glue.
                let (this_tok, this_spacing) = self.eat(true);
                match this_tok.kind {
                    TokenKind::DocComment(..) => {
                        // We will ignore doc comments for now.
                    }
                    _ => {
                        buf.push(TokenTree::Token(this_tok, this_spacing));
                    }
                }
            }
        }
    }
}
\end{lstlisting}

    \item \label{ap1:token_tree_lex_token_tree_open_delim}Hàm \textit{lex\_token\_tree\_open\_delim}

\begin{lstlisting}
fn lex_token_tree_open_delim(&mut self, open_delim: Delimiter) -> PResult<TokenTree> {
    // The span for beginning of the delimited section.
    let pre_span = self.token.span;

    self.open_delims.push((open_delim, self.token.span));

    // Lex the token trees within the delimiters.
    // We stop at any delimiter so we can try to recover if the user
    // uses an incorrect delimiter.
    let (tts, res) = self.lex_token_trees(/* is_delimited */ true);
    if res.is_err() {
        return Err(res.unwrap_err());
    }

    // Expand to cover the entire delimited token tree.
    let delim_span = DelimSpan::from_pair(pre_span, self.token.span);

    match self.token.kind {
        // Correct delimiter.
        TokenKind::CloseDelim(close_delim) if close_delim == open_delim => {
            self.open_delims.pop();

            // Move past the closing delimiter (ofcourse no glue here).
            self.eat(false);
        }

        // Incorrect delimiter.
        TokenKind::CloseDelim(close_delim) => {
            let err = PError::MismatchedClosingDelimiter {
                delimiter: close_delim,
                unmatched_span: self.token.span,
                unclosed_span: pre_span,
            };

            return Err(vec![err]);
        }
        TokenKind::Eof => {
            // Silently recover, the EOF token will be seen again
            // and an error emitted then. Thus we don't pop from
            // self.open_delims here.
        }
        _ => unreachable!(),
    }

    Ok(TokenTree::Delimited(delim_span, open_delim, tts))
}    
\end{lstlisting}

\end{itemize}

\subsection{Bộ phân tích cú pháp}
\subsubsection{Hàm \textit{parse\_stmt}}
\label{ap1:stmt}
\begin{lstlisting}
pub fn parse_stmt(&mut self) -> PResult<Box<Stmt>> {
  if self.token.is_keyword(Keyword::Set) {
      self.parse_stmt_var_decl()
  } else if self.token.is_keyword(Keyword::When) {
      self.parse_stmt_if()
  } else if self.token.kind == TokenKind::OpenDelim(Delimiter::Brace) {
      self.parse_stmt_block()
  } else if self.token.is_keyword(Keyword::During) {
      self.parse_stmt_while()
  } else if self.token.is_keyword(Keyword::For) {
      self.parse_stmt_for()
  } else if self.token.is_keyword(Keyword::Yeet) {
      self.parse_stmt_return()
  } else if self.token.kind == TokenKind::Semicolon {
      self.parse_stmt_empty()
  } else if self.token.is_keyword(Keyword::Fun) {
      self.parse_stmt_func_decl()
  } else if self.token.is_keyword(Keyword::Add) {
      self.parse_stmt_import()
  } else if self.token.is_keyword(Keyword::Br) {
      self.parse_stmt_break()
  } else if self.token.is_keyword(Keyword::Skip) {
      self.parse_stmt_continue()
  } else if self.token.can_begin_expr() {
      self.parse_stmt_expr()
  } else {
      let err = PError::ExpectedStatement {
          token: TokenType::Token(self.token.kind),
          span: self.token.span,
      };
      return Err(vec![err]);
  }
}
\end{lstlisting}

\subsubsection{Hàm \textit{parse\_stmt\_var\_decl}}
\label{ap1:stmt_decl_var}
\begin{lstlisting}
fn parse_stmt_var_decl(&mut self) -> PResult<Box<Stmt>> {
  if !self.token.is_keyword(Keyword::Set) {
      let err = PError::ExpectedToken {
          expected: vec![TokenType::Keyword(kw::to_symbol(Keyword::Set))],
          found: TokenType::Token(self.token.kind),
          span: self.token.span,
          prev_span: self.prev_token.span,
      };

      return Err(vec![err]);
  }

  let start = self.token.span;
  self.advance(); // 'set'

  let is_mut = if self.token.is_keyword(Keyword::Mut) {
      self.advance(); // 'mut'
      true
  } else {
      false
  };

  let ident = self.parse_ident()?;
  self.expect(TokenKind::Colon)?;
  self.advance(); // ':'
  let ty = self.parse_ty()?;

  let init = if self.token.kind == TokenKind::Eq {
      self.advance(); // expr
      Some(self.parse_expr()?)
  } else {
      None
  };

  self.expect(TokenKind::Semicolon)?;
  let span = start.to(self.token.span);

  self.advance();

  let kind = if let Some(init) = init {
      LocalKind::Init(init)
  } else {
      LocalKind::Decl
  };

  let local = Local {
      is_mut,
      ident,
      ty,
      kind,
      span,
  };
  let kind = StmtKind::Var(Box::new(local));
  let stmt = Box::new(Stmt { kind, span });

  Ok(stmt)
}
\end{lstlisting}

\subsubsection{Hàm \textit{parse\_stmt\_func\_decl}}
\label{ap1:stmt_decl_fun}
\begin{lstlisting}
fn parse_stmt_func_decl(&mut self) -> PResult<Box<Stmt>> {
  if !self.token.is_keyword(Keyword::Fun) {
      let err = PError::ExpectedToken {
          expected: vec![TokenType::Keyword(kw::to_symbol(Keyword::Fun))],
          found: TokenType::Token(self.token.kind),
          span: self.token.span,
          prev_span: self.prev_token.span,
      };
      return Err(vec![err]);
  }
  let start_span = self.token.span;
  self.advance(); // Eat "fn"

  let sig = self.parse_stmt_func_sig()?;
  let body = self.parse_stmt()?;

  let end_span = self.prev_token.span;
  let span = start_span.to(end_span);
  let kind = StmtKind::FuncDecl(Box::new(Fun { sig, body }));
  let stmt = Box::new(Stmt { kind, span });

  Ok(stmt)
}
\end{lstlisting}

\paragraph{Phân tích phần ký hiệu của hàm}.
\label{ap1:stmt_decl_fun_sig}
\begin{lstlisting}
fn parse_stmt_func_sig(&mut self) -> PResult<FunSig> {
  let start = self.token.span;
  let name = self.parse_ident()?;

  self.expect(TokenKind::OpenDelim(Delimiter::Parenthesis))?;
  self.advance();

  let mut inputs: Vec<FunParam> = Vec::new();
  loop {
      if self.token.is_close_delim(Delimiter::Parenthesis) {
          break;
      }

      let start = self.token.span;

      let is_mut = if self.token.is_keyword(Keyword::Mut) {
          self.advance(); // Eat 'mut'
          true
      } else {
          false
      };

      let ident = self.parse_ident()?;

      self.expect(TokenKind::Colon)?;
      self.advance(); // Eat ':'

      let ty = self.parse_ty()?;
      let end = self.prev_token.span;
      inputs.push(FunParam {
          ident,
          ty,
          is_mut,
          span: start.to(end),
      });

      if self.token.kind != TokenKind::Comma {
          break;
      }

      self.advance(); // Eat ','
  }

  self.expect(TokenKind::CloseDelim(Delimiter::Parenthesis))?;
  self.advance(); // Eat ')'

  let output = if self.token.kind == TokenKind::RArrow {
      self.advance(); // Eat '->'
      Some(self.parse_ty()?)
  } else {
      None
  };

  let end = self.prev_token.span;
  let span = start.to(end);

  Ok(FunSig {
      name,
      inputs,
      output,
      span,
  })
}
\end{lstlisting}

\subsubsection{Hàm \textit{parse\_stmt\_if}}
\label{ap1:stmt_when}
\begin{lstlisting}
fn parse_stmt_if(&mut self) -> PResult<Box<Stmt>> {
  if !self.token.is_keyword(Keyword::When) {
      let err = PError::ExpectedToken {
          expected: vec![TokenType::Keyword(kw::to_symbol(Keyword::When))],
          found: TokenType::Token(self.token.kind),
          span: self.token.span,
          prev_span: self.prev_token.span,
      };

      return Err(vec![err]);
  }

  let start_span = self.token.span;
  self.advance(); // Eat token after "if"
                  // Parse the condition expression.
  let condition = self.parse_expr()?;
  // Parse the block for the `if` statement.
  let if_block = self.parse_stmt()?;

  // Optionally parse an `else` block.
  let else_block = if self.token.is_keyword(Keyword::Alt) {
      self.advance(); // Eat token after `else`
      let else_block = self.parse_stmt()?;
      Some(else_block)
  } else {
      None
  };

  let end_span = self.prev_token.span;
  let span = start_span.to(end_span);
  let kind = StmtKind::If(condition, if_block, else_block);
  let stmt = Box::new(Stmt { kind, span });

  Ok(stmt)
}
\end{lstlisting}

\subsubsection{Hàm \textit{parse\_stmt\_while}}
\label{ap1:stmt_during}
\begin{lstlisting}
fn parse_stmt_while(&mut self) -> PResult<Box<Stmt>> {
  if !self.token.is_keyword(Keyword::During) {
      let err = PError::ExpectedToken {
          expected: vec![TokenType::Keyword(kw::to_symbol(Keyword::During))],
          found: TokenType::Token(self.token.kind),
          span: self.token.span,
          prev_span: self.prev_token.span,
      };

      return Err(vec![err]);
  }

  let start_span = self.token.span;
  self.advance();

  let condition = self.parse_expr()?;
  let block = self.parse_stmt()?;
  let end_span = self.prev_token.span;
  let span = start_span.to(end_span);
  let kind = StmtKind::While(condition, block);
  let stmt = Box::new(Stmt { kind, span });

  Ok(stmt)
}
\end{lstlisting}

\subsubsection{Hàm \textit{parse\_stmt\_for}}
\label{ap1:stmt_for}
\begin{lstlisting}
fn parse_stmt_for(&mut self) -> PResult<Box<Stmt>> {
  if !self.token.is_keyword(Keyword::For) {
      let err = PError::ExpectedToken {
          expected: vec![TokenType::Keyword(kw::to_symbol(Keyword::For))],
          found: TokenType::Token(self.token.kind),
          span: self.token.span,
          prev_span: self.prev_token.span,
      };

      return Err(vec![err]);
  }

  let start_span = self.token.span;

  self.advance();
  let ident = self.parse_ident()?;

  if !self.token.is_keyword(Keyword::In) {
      let err = PError::ExpectedToken {
          expected: vec![TokenType::Keyword(kw::to_symbol(Keyword::In))],
          found: TokenType::Token(self.token.kind),
          span: self.token.span,
          prev_span: self.prev_token.span,
      };

      return Err(vec![err]);
  }

  self.advance();
  let expr = self.parse_expr()?;
  let block = self.parse_stmt()?;
  let end_span = self.prev_token.span;
  let span = start_span.to(end_span);
  let kind = StmtKind::For(ident, expr, block);
  let stmt = Box::new(Stmt { kind, span });

  Ok(stmt)
}
\end{lstlisting}

\subsubsection{Hàm \textit{parse\_stmt\_return}}
\label{ap1:stmt_yeet}
\begin{lstlisting}
fn parse_stmt_return(&mut self) -> PResult<Box<Stmt>> {
  if !self.token.is_keyword(Keyword::Yeet) {
      let err = PError::ExpectedToken {
          expected: vec![TokenType::Keyword(kw::to_symbol(Keyword::Yeet))],
          found: TokenType::Token(self.token.kind),
          span: self.token.span,
          prev_span: self.prev_token.span,
      };

      return Err(vec![err]);
  }

  let start_span = self.token.span;
  self.advance();
  let kind = if self.token.can_begin_expr() {
      let expr = self.parse_expr()?;
      self.expect(TokenKind::Semicolon)?;
      self.advance();
      StmtKind::Return(Some(expr))
  } else {
      self.expect(TokenKind::Semicolon)?;
      self.advance();
      StmtKind::Return(None)
  };

  Ok(Box::new(Stmt {
      kind,
      span: start_span.to(self.prev_token.span),
  }))
}
\end{lstlisting}

\subsubsection{Hàm \textit{parse\_stmt\_empty}}
\label{ap1:stmt_semicolon}
\begin{lstlisting}
pub fn parse_stmt_empty(&mut self) -> PResult<Box<Stmt>> {
    self.expect(TokenKind::Semicolon)?;
    let span = self.token.span;
    self.advance();
    Ok(Box::new(Stmt {
        kind: StmtKind::Empty,
        span,
    }))
}
\end{lstlisting}

\subsubsection{Hàm \textit{parse\_stmt\_block}}
\label{ap1:stmt_block}
\begin{lstlisting}
pub fn parse_stmt_block(&mut self) -> PResult<Box<Stmt>> {
  self.expect(TokenKind::OpenDelim(Delimiter::Brace))?;
  let start = self.token.span;
  self.advance();

  let mut stmts = Vec::new();
  let mut errors: Vec<PError> = Vec::new();
  while self.token.kind != TokenKind::CloseDelim(Delimiter::Brace) {
      let result = self.parse_stmt();

      if let Err(mut err) = result {
          errors.append(&mut err);

          // recover may eat the closing brace, so we need to check again
          if self.token.kind != TokenKind::CloseDelim(Delimiter::Brace) {
              self.recover();
          }

          continue;
      }

      let stmt = result.unwrap();
      stmts.push(stmt);
  }

  let end = self.token.span;
  let span = start.to(end);
  let kind = StmtKind::Block(stmts);
  let stmt = Box::new(Stmt { kind, span });

  self.expect(TokenKind::CloseDelim(Delimiter::Brace))?;
  self.advance();

  if errors.is_empty() {
      Ok(stmt)
  } else {
      Err(errors)
  }
}
\end{lstlisting}

\subsubsection{Hàm \textit{parse\_stmt\_import}}
\label{ap1:stmt_add}
\begin{lstlisting}
fn parse_stmt_import(&mut self) -> PResult<Box<Stmt>> {
  if !self.token.is_keyword(Keyword::Add) {
      let err = PError::ExpectedToken {
          expected: vec![TokenType::Keyword(kw::to_symbol(Keyword::Add))],
          found: TokenType::Token(self.token.kind),
          span: self.token.span,
          prev_span: self.prev_token.span,
      };

      return Err(vec![err]);
  }

  let start_span = self.token.span;
  self.advance(); // Eat "import"

  let path = self.parse_ident()?;
  self.expect(TokenKind::Semicolon)?;
  let span = start_span.to(self.token.span);
  self.advance();

  let kind = StmtKind::Import(path);
  let stmt = Box::new(Stmt { kind, span });

  Ok(stmt)
}
\end{lstlisting}

\subsubsection{Hàm \textit{parse\_stmt\_break}}
\label{ap1:stmt_br}
\begin{lstlisting}
fn parse_stmt_break(&mut self) -> PResult<Box<Stmt>> {
  if !self.token.is_keyword(Keyword::Br) {
      let err = PError::ExpectedToken {
          expected: vec![TokenType::Keyword(kw::to_symbol(Keyword::Br))],
          found: TokenType::Token(self.token.kind),
          span: self.token.span,
          prev_span: self.prev_token.span,
      };

      return Err(vec![err]);
  }

  let span = self.token.span;
  self.advance(); // Eat token after "exit"

  self.expect(TokenKind::Semicolon)?;
  let span = span.to(self.token.span);
  self.advance();

  Ok(Box::new(Stmt {
      kind: StmtKind::Break,
      span,
  }))
}
\end{lstlisting}

\subsubsection{Hàm \textit{parse\_stmt\_continue}}
\label{ap1:stmt_skip}
\begin{lstlisting}
fn parse_stmt_continue(&mut self) -> PResult<Box<Stmt>> {
  if !self.token.is_keyword(Keyword::Skip) {
      let err = PError::ExpectedToken {
          expected: vec![TokenType::Keyword(kw::to_symbol(Keyword::Skip))],
          found: TokenType::Token(self.token.kind),
          span: self.token.span,
          prev_span: self.prev_token.span,
      };
      return Err(vec![err]);
  }
  let span = self.token.span;
  self.advance(); // Eat token after "skip"
  self.expect(TokenKind::Semicolon)?;
  let span = span.to(self.token.span);
  self.advance();
  Ok(Box::new(Stmt {
      kind: StmtKind::Continue,
      span,
  }))
}
\end{lstlisting}

\subsubsection{Hàm \textit{parse\_stmt\_expr}}
\label{ap1:stmt_expr}
\begin{lstlisting}
pub fn parse_stmt_expr(&mut self) -> PResult<Box<Stmt>> {
  let expr = self.parse_expr()?;
  let span = expr.span;
  let stmt = Box::new(Stmt {
      kind: StmtKind::Expr(expr),
      span,
  });

  self.expect(TokenKind::Semicolon)?;
  self.advance();

  Ok(stmt)
}
\end{lstlisting}

\subsubsection{Hàm \textit{parse\_expr}}
\label{ap1:expr}
\begin{lstlisting}
pub fn parse_expr(&mut self) -> PResult<Box<Expr>> {
  let lhs = self.parse_expr_prefix()?;
  self.parse_expr_rest(0, lhs)
}
\end{lstlisting}

\paragraph{Hàm \textit{parse\_expr\_prefix}}
\label{ap1:expr_prefix}
\begin{lstlisting}
fn parse_expr_prefix(&mut self) -> PResult<Box<Expr>> {
  match self.token.kind {
      TokenKind::Not => {
          let start = self.token.span;
          self.advance();
          let expr = self.parse_expr_prefix()?;
          let span = start.to(expr.span);
          let expr = self.mk_unary(UnOp::Not, expr);
          Ok(self.mk_expr(expr, span))
      }
      TokenKind::BinOp(BinOpToken::Minus) => {
          let start = self.token.span;
          self.advance();
          let expr = self.parse_expr_prefix()?;
          let span = start.to(expr.span);
          let expr = self.mk_unary(UnOp::Ne, expr);
          Ok(self.mk_expr(expr, span))
      }
      _ => self.parse_expr_dot_or_call(),
  }
}
\end{lstlisting}

\paragraph{Hàm \textit{parse\_expr\_dot\_or\_call}}
\label{ap1:expr_dot_or_call}
\begin{lstlisting}
fn parse_expr_dot_or_call(&mut self) -> PResult<Box<Expr>> {
  let base = self.parse_expr_bottom()?;
  if self.token.is_kind(TokenKind::Dot)
      || self.token.is_open_delim(Delimiter::Parenthesis)
      || self.token.is_open_delim(Delimiter::Bracket)
  {
      self.parse_expr_dot_or_call_with(base)
  } else {
      Ok(base)
  }
}
\end{lstlisting}

\paragraph{Hàm \textit{parse\_expr\_bottom}}
\label{ap1:expr_bottom}
\begin{lstlisting}
fn parse_expr_bottom(&mut self) -> PResult<Box<Expr>> {
  match self.token.kind {
      TokenKind::Literal(_) => self.parse_expr_lit(),
      TokenKind::Ident(_, _) => self.parse_expr_ident(),
      TokenKind::OpenDelim(Delimiter::Parenthesis) => {
          self.parse_expr_grouped(Delimiter::Parenthesis)
      }
      TokenKind::OpenDelim(Delimiter::Bracket) => self.parse_expr_array(),
      _ => {
          let err = PError::ExpectedToken {
              expected: vec![
                  TokenType::Const,
                  TokenType::Ident,
                  TokenType::Token(TokenKind::OpenDelim(Delimiter::Parenthesis)),
                  TokenType::Token(TokenKind::OpenDelim(Delimiter::Bracket)),
              ],
              found: TokenType::Token(self.token.kind.clone()),
              span: self.token.span,
              prev_span: self.prev_token.span,
          };

          return Err(vec![err]);
      }
  }
}
\end{lstlisting}

\paragraph{Hàm \textit{parse\_expr\_dot\_or\_call\_with}}
\label{ap1:expr_dot_or_call_with}
\begin{lstlisting}
fn parse_expr_dot_or_call_with(&mut self, base: Box<Expr>) -> PResult<Box<Expr>> {
  debug_assert!(
      self.token.is_kind(TokenKind::Dot)
          || self.token.is_open_delim(Delimiter::Parenthesis)
          || self.token.is_open_delim(Delimiter::Bracket)
  );

  let mut base = base;
  loop {
      if self.token.kind == TokenKind::Dot {
          base = self.parse_expr_dot(base)?;
      } else if self.token.is_open_delim(Delimiter::Parenthesis) {
          base = self.parse_expr_call_with(base)?;
      } else if self.token.is_open_delim(Delimiter::Bracket) {
          base = self.parse_expr_array_index(base)?;
      } else {
          break;
      }
  }

  Ok(base)
}
\end{lstlisting}

\paragraph{Hàm \textit{parse\_expr\_rest}}
\label{ap1:expr_rest}
\begin{lstlisting}
fn parse_expr_rest(&mut self, min_prec: usize, mut lhs: Box<Expr>) -> PResult<Box<Expr>> {
  self.expected_tokens.push(TokenType::Operator);

  loop {
      let op_assoc = AssocOp::from_token(&self.token);
      if op_assoc.is_none() {
          break;
      }
      let op_assoc = op_assoc.unwrap();
      let prec = op_assoc.precedence();
      if prec < min_prec {
          break;
      }

      let lhs_span = lhs.span;

      // Special cases:
      if op_assoc == AssocOp::As {
          lhs = self.parse_assoc_op_cast(lhs, lhs_span, ExprKind::Cast)?;
          continue;
      }

      let op_span = self.token.span;
      self.advance();

      let mut rhs = self.parse_expr_prefix()?;
      let fixity = op_assoc.fixity();
      let next_prec = match fixity {
          Fixity::Left => prec + 1,
          Fixity::Right => prec,
      };
      rhs = self.parse_expr_rest(next_prec, rhs)?;
      let span = self.mk_expr_sp(&lhs, rhs.span);
      lhs = match op_assoc {
          AssocOp::Add
          | AssocOp::Subtract
          | AssocOp::Multiply
          | AssocOp::Divide
          | AssocOp::Modulus
          | AssocOp::LAnd
          | AssocOp::LOr
          | AssocOp::BitXor
          | AssocOp::BitAnd
          | AssocOp::BitOr
          | AssocOp::ShiftLeft
          | AssocOp::ShiftRight
          | AssocOp::Equal
          | AssocOp::Less
          | AssocOp::LessEqual
          | AssocOp::NotEqual
          | AssocOp::Greater
          | AssocOp::GreaterEqual => {
              let ast_op = op_assoc.to_ast_binop().unwrap();
              let binary = self.mk_binary(span_encoding::respan(ast_op, op_span), lhs, rhs);
              self.mk_expr(binary, span)
          }
          AssocOp::Assign => self.mk_expr(ExprKind::Assign(lhs, rhs, op_span), span),
          AssocOp::AssignOp(k) => {
              let aop = match k {
                  BinOpToken::Plus => BinOpKind::Add,
                  BinOpToken::Minus => BinOpKind::Sub,
                  BinOpToken::Star => BinOpKind::Mul,
                  BinOpToken::Slash => BinOpKind::Div,
                  BinOpToken::Percent => BinOpKind::Mod,
                  BinOpToken::Caret => BinOpKind::BitXor,
                  BinOpToken::And => BinOpKind::BitAnd,
                  BinOpToken::Or => BinOpKind::BitOr,
                  BinOpToken::Shl => BinOpKind::Shl,
                  BinOpToken::Shr => BinOpKind::Shr,
              };
              let aopexpr = self.mk_assign_op(span_encoding::respan(aop, op_span), lhs, rhs);
              self.mk_expr(aopexpr, span)
          }
          AssocOp::As => unreachable!("AssocOp::As should be handled separately"),
      }
  }

  Ok(lhs)
}
\end{lstlisting}

\paragraph{Hàm \textit{parse\_expr\_dot}}
\label{ap1:expr_dot}
\begin{lstlisting}
fn parse_expr_dot(&mut self, base: Box<Expr>) -> PResult<Box<Expr>> {
  debug_assert!(self.token.is_kind(TokenKind::Dot));
  let start = self.token.span;
  self.advance();
  let field = self.parse_ident()?;
  let span = start.to(field.span);
  let dot = ExprKind::LibAccess(base, field);
  Ok(self.mk_expr(dot, span))
}
\end{lstlisting}

\paragraph{Hàm \textit{parse\_expr\_call\_with}}
\label{ap1:expr_call_with}
\begin{lstlisting}
fn parse_expr_call_with(&mut self, base: Box<Expr>) -> PResult<Box<Expr>> {
  debug_assert!(self.token.is_open_delim(Delimiter::Parenthesis));
  self.advance();

  let is_lib_func = match base.kind {
      ExprKind::LibAccess(..) => true,
      _ => false,
  };

  let mut args = Vec::new();
  loop {
      if self.token.is_close_delim(Delimiter::Parenthesis) {
          break;
      }

      let arg = self.parse_expr()?;
      args.push(arg);

      if !self.token.is_kind(TokenKind::Comma) {
          break;
      }

      self.advance(); // eat comma
  }

  self.expect(TokenKind::CloseDelim(Delimiter::Parenthesis))?;

  let span = self.mk_expr_sp(&base, self.token.span);
  let call = if is_lib_func {
      ExprKind::LibFunCall(base, args)
  } else {
      ExprKind::FunCall(base, args)
  };
  self.advance();

  Ok(self.mk_expr(call, span))
}
\end{lstlisting}

\paragraph{Hàm \textit{parse\_expr\_array\_index}}
\label{ap1:expr_array_index}
\begin{lstlisting}
fn parse_expr_array_index(&mut self, base: Box<Expr>) -> PResult<Box<Expr>> {
  debug_assert!(self.token.is_open_delim(Delimiter::Bracket));
  let start = self.token.span;
  self.advance();
  let index = self.parse_expr()?;
  let index_span = index.span;
  self.expect(TokenKind::CloseDelim(Delimiter::Bracket))?;
  let span = start.to(self.token.span);
  self.advance();
  let index = self.mk_expr(ExprKind::Index(base, index, index_span), span);
  Ok(index)
}
\end{lstlisting}
}

\paragraph{Hàm \textit{}}
\label{ap1:}
\begin{lstlisting}

\end{lstlisting}

\begin{lstlisting}

\end{lstlisting}