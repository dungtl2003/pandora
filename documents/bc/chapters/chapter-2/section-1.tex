\section{Phân tích từ vựng}
\subsection{Mục đích và nhiệm vụ}
Nhiệm vụ chính của phần phân tích từ vựng là đọc các ký tự vào từ văn bản chương trình nguồn và đưa ra lần lượt các từ tố cùng một số thông tin thuộc tính.

\vspace{1cm}
\hspace{-1cm}
\begin{tikzpicture}[
    % roundnode/.style={circle, draw=green!60, fill=green!5, very thick, minimum size=7mm},
    squarednode/.style={rectangle, draw=red!60, fill=red!5, very thick, minimum size=5mm},
    ]
    %Nodes
    \node[squarednode,text width=2.5cm,align=center](lexer){Phân tích từ vựng};
    \node[text width=3cm,align=center](source)[left=of lexer]{Chương trình nguồn};
    \node[squarednode,text width=3cm,align=center](parser)[right=of lexer,xshift = 2cm] {Phân tích cú pháp};
    \node[squarednode,text width=3cm,align=center](tableofsymbols)[below=of lexer, xshift = 3cm] {Bảng ký hiệu};
    \node[](nothing)[right=of parser]{}; 
    \node[text width=5cm,align=center](textabove)[above=of lexer,xshift = 3cm, yshift = -1.2cm]{Yêu cầu lấy từ tố tiếp theo}; 
    \node[text width=3cm,align=center](textbelow)[below=of lexer,xshift = 3cm, yshift = 1.2cm]{Từ tố}; 

    %Lines
    \draw[->] (source) -- (lexer);
    \draw[->] ([yshift = 2mm]lexer.east) -- ([yshift = 2mm]parser.west);
    \draw[<->] (lexer.south) -- ([yshift = 2mm]tableofsymbols.west);
    \draw[->] ([yshift = -2mm]parser.west) -- ([yshift = -2mm]lexer.east) ;
    \draw[<->] (tableofsymbols.east) -- ([xshift = 3cm]parser.south);
    \draw[->,dashed] (parser.east) -- (nothing.west) ;
\end{tikzpicture}
\vspace{1cm}


Phần này có thể coi là phần tiền xử lý văn bản chương trình nguồn, làm cho nhiệm vụ của các giai đoạn sau đơn giản hơn. Quá trình này bao gồm các công việc:

1. {\itshape Xóa bỏ các ký tự không có nghĩa.} Các chú thích, dòng trống, các ký tự xuống dòng, dấu tab, các khoảng trắng không cần thiết đều bị xóa bỏ.

2. {\itshape Nhận dạng các ký hiệu.} Nhận dạng các ký tự liền nhau tạo thành một ký hiệu. Các dạng ký hiệu này gọi là các từ tố. Các từ tố có thể là:

a. Từ khóa như \textbf{when, for, \dots};

b. Tên của biến, hàm, \dots;

c. Các số như 12, 4, 3.14, \dots;

d. Xâu, nằm trong cặp dấu nháy kép (")

e. Ký tự, nằm trong cặp dấu nháy đơn (')

\dots

3. {\itshape Số hóa ký hiệu.} Do các con số được xử lí dễ dàng hơn là các xâu, từ khóa, tên nên các xâu sẽ được thay bằng số, các chứ số sẽ được đổi thành số thật sự biểu diễn trong máy. Quá trình này được gọi là số hóa.

Ngoài ra, bộ phân tích từ vựng còn làm một nhiệm vụ phụ: đóng vai trò giao diện với người dùng. Nó xóa bỏ các ký tự thừa như các khoảng trắng, các chú thích, các ký tự hết dòng\dots\space làm cho chương trình không phụ thuộc vào chúng. Như vậy cũng có nghĩa nó cho phép người lập trình trình bày chương trình nguồn của mình tùy ý và dễ đọc hơn. Mặt khác, đây là phần duy nhất lưu các thông tin phụ về từ tố như số dòng, số cột của nó, \dots\space cho phép bộ phận báo lỗi chỉ chính xác nơi xảy ra lỗi trong chương trình nguồn. Nếu ngôn ngữ nguồn cho phép dùng các hàm macro, thì việc xử lí các macro cũng thường được đặt trong phần này.

\subsection{Sự cần thiết phải tách rời phân tích từ vựng với phân tích cú pháp}
Như trên đã trình bày, phần phân tích của chương trình dịch bao gồm 3 phần là: phân tích từ vựng, phân tích cú pháp, phân tích ngữ nghĩa. Trước đây phần phân tích từ vựng và phân tích cú pháp có thể viết chung làm một khối. Bây giờ có một số lý do để ta nên chia hai phần phân tích này tách rời nhau:

1. Thiết kế từng phần đơn giản hơn. Đây là lý do quan trọng nhất, phù hợp với các quy tắc thiết kế và bảo dưỡng chương trình.

2. Tính năng của chương trình dịch được cải tiến. Bộ phân tích từ vựng có thể cải tiến để nâng cao tốc độ phân tích, bộ phân tích cú pháp phân tích được các cấu trúc phức tạp hơn. Ngoài ra, có một số công cụ trợ giúp chỉ có thể thêm vào sau khi hai bộ phận này đã được tách rời nhau.

3. Cho phép chương trình dịch có thể chuyển đổi. Ví dụ như khi thay đổi bảng mã ký tự, quy ước lại các ký hiệu \dots\space thì việc sửa đổi sẽ ít, dễ dàng và chính xác hơn.

Phân tích từ vựng là phần đơn giản nhất của chương trình dịch. Tuy vậy, nó lại chiếm một phần khá lớn trong tổng số thời gian dịch (thường chiếm 20-40\%) do phải làm việc trực tiếp với chương trình nguồn ghi trên các thiết bị lưu trữ ngoài có tốc độ chậm (như ổ đĩa), điều đó cũng có nghĩa tác dụng cải tiến của nó đặc biệt quan trọng.

\subsection{Các giai đoạn phân tích từ vựng}
Quy trình phân tích cú pháp trong hệ thống của chúng em bao gồm ba giai đoạn chính. Đầu tiên, mã nguồn được chia nhỏ thành các từ tố sơ cấp (\textit{Token trong gói lexer}) – những phần tử cơ bản nhất như tên, toán tử, và ký tự đặc biệt, \dots Sau đó, ở giai đoạn tiếp theo, các token sơ cấp này được xử lý để tạo thành token thứ cấp (\textit{Token trong gói ast}) bằng cách loại bỏ các khoảng trắng, comment không cần thiết và kết hợp các token có thể ghép lại, ví dụ như '<' và '=' thành "<=". Cuối cùng, các token thứ cấp được nhóm lại để tạo thành cây từ tố (\textit{TokenTree trong gói ast::tokenstream}), giúp biểu diễn cấu trúc cú pháp của mã nguồn, tạo nền tảng cho quá trình phân tích cú pháp, phân tích ngữ nghĩa và biên dịch. Chi tiết sẽ được chúng em trình bày như dưới đây:

\textbf{Giai đoạn 1.} \textit{Phân tích từ tố sơ cấp}:

Từ tố sơ cấp bao gồm các thuộc tính là loại từ tố và độ dài của từ tố:

\clearpage
\begin{lstlisting}[]
  pub struct Token {
    pub kind: TokenKind,
    pub len: u32,
  }
\end{lstlisting}

Ở giai đoạn này, bộ phân tích từ vựng sẽ đọc chương trình nguồn và phân tích nó thành các từ tố sơ cấp. Các loại từ tố sơ cấp được thể hiện như sau:

\begin{itemize}
  \item Các ký tự đơn: 
  \begin{lstlisting}[]
    pub enum TokenKind {
      /* one char symbol */
      /// :
      Colon,
      /// ,
      Comma,
      /// .
      Dot,
      /// ;
      Semicolon,
      /// ?
      Question,
      /// (
      OpenParen,
      /// )
      CloseParen,
      /// {
      OpenBrace,
      /// }
      CloseBrace,
      /// [
      OpenBracket,
      /// ]
      CloseBracket,
      /// `!`
      Bang,
      /// `=`
      Eq,
      /// `>`
      Gt,
      /// `<`
      Lt,
      /// `~`
      Tilde,
      /// `+`
      Plus,
      /// `-`
      Minus,
      /// `*`
      Star,
      /// `/`
      Slash,
      /// `%`
      Percent,
      /// `^`
      Caret,
      /// `&`
      And,
      /// `|`
      Or,

      ...
    }
  \end{lstlisting}
  \item Các chuỗi ký tự:
  \begin{lstlisting}[]
    pub enum TokenKind {
      ...
  
      // Literal
      Literal(LiteralKind),
  
      ...
    }
  \end{lstlisting}

    LiteralKind là kiểu của chuỗi ký tự, nó được thể hiện như sau:

    \begin{lstlisting}[]
    pub enum LiteralKind {
      /// `"abc"`, `"ab`, `"ab\"`, `"ab\""`.
      Str {
          terminated: bool,
      },
      /// `r#"abc"#`, `r###"ab"##c"###`, `r###"ab"######`, None means invalid.
      RawStr {
          n_hashes: Option<u8>,
      },
      /// `1_000`, `0b1101`, `0o657`, `0h1af9`.
      Int {
          base: Base,
          empty_int: bool,
      },
      Float {
          base: Base,
          empty_exponent: bool,
      },
      // Although kind can be Char but it can be many symbols (error). Ex: 'abc' -> error.
      /// `'a'`, `'\''`, `'\\'`, `'abc'`, `'ab`.
      Char {
          terminated: bool,
      },
    }
    \end{lstlisting}
    \begin{itemize}
      \item Chuỗi (Str). Loại từ tố này có thêm thuộc tính \textit{terminated} để xác định xem chuỗi có được đóng đúng cách hay không, ở đây chuỗi được đặt đúng cách là bên trong cặp nháy kép (").
      \item Chuỗi thô (RawStr). Loại từ tố này đại diện cho chuỗi được giữ nguyên giá trị và không bị xử lý đặc biệt bởi trình biên dịch. Điều này có nghĩa là tất cả các ký tự trong chuỗi, bao gồm cả các ký tự đặc biệt như '\textbackslash', sẽ được giữ nguyên khi chúng xuất hiện. Trong khi đó ở chuỗi thông thường, nếu muốn trình biên dịch hiểu được là '\textbackslash' thì ta cần truyền giá trị dưới dạng là '\textbackslash\textbackslash'; hoặc ví dụ khác chuỗi thông thường sẽ hiểu '\textbackslash n' là ký tự xuống dòng, nhưng trong chuỗi thô "\textbackslash n" sẽ được hiểu là 2 ký tự '\textbackslash' và 'n'; \dots\space Và nhiều ví dụ khác nữa. 
      \\Chuỗi thô sẽ được đặt trong cặp nháy kép (") bắt đầu với \textit{r}.
      \\Loại từ tố này có thêm thuộc tính \textit{n\_hashes} để đếm số kí tự '\#' nằm giữa kí tự 'r' và '"'. Nếu chuỗi bị sai, \textit{n\_hashes} sẽ mang giá trị None
      \item Số nguyên (Int). Loại từ tố này có thêm 2 thuộc tính \textit{base} và \\\textit{empty\_int}. Thuộc tính \textit{base} dùng để xác định hệ cơ số của số nguyên (ở đây Pandora hỗ trợ 4 cơ số chính là thập phân, nhị phân, bát phân và thập lục phân). Thuộc tính \textit{empty\_int} để xác định xem số nguyên có hợp lệ hay không (ví dụ 0b, 0h, 0o).
      \item Số thực (Float). Loại từ tố này có thêm 2 thuộc tính là \textit{base} và \\\textit{empty\_exponent}. Thuộc tính \textit{base} tương tự như số nguyên, nó dùng để xác định hệ cơ số của số thực. Thuộc tính \textit{empty\_exponent} dùng để xác định xem số nguyên có hợp lệ hay không (phải có phần số mũ sau chữ \textit{e}, ví dụ: không hợp lệ - 314e, hợp lệ - 314e-2).
      \item Ký tự (Char). Loại từ tố này có thêm thuộc tính \textit{terminated} để xác định xem ký tự có được đóng đúng cách hay không, ở đây ký tự được đặt đúng cách là bên trong cặp nháy đơn (').
      
    \end{itemize}
  \item Tên: Tên biến, hàm , \dots\space và từ khóa. (Từ khóa và các tên thông thường sẽ được phân biệt ở giai đoạn sau)
        \begin{lstlisting}[]
          pub enum TokenKind {
            ...
        
            // Identifier
            Ident,
        
            ...
          }
        \end{lstlisting}
  \item Tên thô: tương tự như tên thông thường nhưng ở đây ta có thể sử dụng từ khóa để đặt tên cho biến, hàm, \dots
        \begin{lstlisting}[]
          pub enum TokenKind {
            ...
        
            // Raw identifier
            RawIdent,
        
            ...
          }
        \end{lstlisting}
  \item Chú thích dòng - LineComment: Chú thích theo dòng. 
        \begin{lstlisting}[]
          pub enum TokenKind {
            ...
        
            // Comments
            LineComment {
                doc_style: Option<DocStyle>,
            },

            ...
          }
        \end{lstlisting}
        Loại từ tố này có thêm thuộc tính \textit{doc\_style} dùng để xác định kiểu của chú thích là bên trong hay bên ngoài 1 khối lệnh.
        \begin{lstlisting}[]
          pub enum DocStyle {
            Inner,
            Outer,
          }
        \end{lstlisting}
  \item Chú thích:  Chú thích theo đoạn. 
        \begin{lstlisting}
          pub enum TokenKind {
            ...

            BlockComment {
                doc_style: Option<DocStyle>,
                terminated: bool,
            },

            ...
          }
        \end{lstlisting}
        Loại từ tố này có thêm 2 thuộc tính là \textit{doc\_style} và \textit{terminated}. Thuộc tính \textit{doc\_style} có chức năng tương tự như chú thích dòng, để xác định kiểu của chú thích. Thuộc tính \textit{terminated} dùng để xác định xem chú thích có được đóng đúng cách không.
  \item Khoảng trắng.
        \begin{lstlisting}
          pub enum TokenKind {
            ...

            Whitespace,

            ...
          }
        \end{lstlisting}
  \item Không xác định.
        \begin{lstlisting}
          pub enum TokenKind {
            ...
            
            // Unknown token's kind.
            Unknown,
            
            ...
          }
        \end{lstlisting}
  \item Kết thúc đầu vào.
        \begin{lstlisting}
          pub enum TokenKind {
            ...
            
            /// End of input.
            Eof,
          }
        \end{lstlisting}
\end{itemize}

Hàm \textit{advance\_token} được sử dụng để đọc từ tố tiếp theo trong chuỗi ký tự đầu vào như sau:
\begin{lstlisting}[]
  pub fn advance_token(&mut self) -> Token {
    self.reset_bytes_eaten();

    let first_char = match self.eat() {
        Some(c) => c,
        None => return Token::new(TokenKind::Eof, 0),
    };

    let kind = match first_char {
        c if is_whitespace(c) => self.whitespace(),

        ':' => TokenKind::Colon,
        ',' => TokenKind::Comma,
        '.' => TokenKind::Dot,
        ';' => TokenKind::Semicolon,
        '?' => TokenKind::Question,
        '(' => TokenKind::OpenParen,
        ')' => TokenKind::CloseParen,
        '[' => TokenKind::OpenBracket,
        ']' => TokenKind::CloseBracket,
        '{' => TokenKind::OpenBrace,
        '}' => TokenKind::CloseBrace,
        '!' => TokenKind::Bang,
        '=' => TokenKind::Eq,
        '>' => TokenKind::Gt,
        '<' => TokenKind::Lt,
        '~' => TokenKind::Tilde,
        '+' => TokenKind::Plus,
        '-' => TokenKind::Minus,
        '*' => TokenKind::Star,
        '%' => TokenKind::Percent,
        '^' => TokenKind::Caret,
        '&' => TokenKind::And,
        '|' => TokenKind::Or,

        // Slash, comment or block comment.
        '/' => match self.first() {
            '/' => self.line_comment(),
            '*' => self.block_comment(),
            _ => TokenKind::Slash,
        },

        '0'..='9' => self.number(),

        // Raw identifier, Identifier, Raw double quote string
        'r' => match (self.first(), self.second()) {
            ('#', c1) if is_id_start(c1) => self.raw_identifier(),
            ('#', _) | ('"', _) => {
                let res = self.raw_double_quote_string();
                TokenKind::Literal(LiteralKind::RawStr { n_hashes: res.ok() })
            }
            _ => self.identifier(),
        },

        '\'' => self.single_quote_string(),
        '"' => self.double_quote_string(),

        c if is_id_start(c) => self.identifier(),

        _ => TokenKind::Unknown,
    };

    Token::new(kind, self.bytes_eaten())
  } 
\end{lstlisting}

Cụ thể:
\begin{itemize}
  \item Khoảng trắng sẽ được chuyển trực tiếp thành từ tố khoảng trắng.
  \item Các ký tự đơn như ':', ',', \dots , '|' sẽ được chuyển trực tiếp thành các loại từ tố tương ứng.
  \item Ký tự '/' đặc biệt hơn vì có thể nó sẽ là bắt đầu của 1 chú thích nên ta cần kiểm tra ký tự ngay sau nó, nếu là '/' thì đây là loại từ tố \textit{line\_comment}, nếu là '*' thì đây là loại từ tố \textit{block\_comment}, ngược lại ký tự tiếp theo này là 1 ký tự khác thì đây là loại từ tố \textit{Slash}.
  \item Nếu là số thì các loại từ tố số sẽ được xác định cụ thể là Int hay Float, cơ số nào bởi hàm \textit{number}.
  % \begin{lstlisting}[]
  %   fn number(&mut self) -> TokenKind {
  %     debug_assert!('0' <= self.prev() && self.prev() <= '9');

  %     let mut base: Base = Base::Decimal;
  %     if self.prev() == '0' {
  %         // Both binary and octal can have digit from 0 to 9 (for now). We will validate those
  %         // when "cooking" tokens for better error diagnostic.
  %         // If not error, we will not return result immediately to scan more.
  %         match self.first() {
  %             'b' | 'B' => {
  %                 self.eat();
  %                 base = Base::Binary;
  %                 if !self.eat_decimal_digits() {
  %                     return TokenKind::Literal(LiteralKind::Int {
  %                         base,
  %                         empty_int: true,
  %                     });
  %                 }
  %             }
  %             'o' | 'O' => {
  %                 self.eat();
  %                 base = Base::Octal;
  %                 if !self.eat_decimal_digits() {
  %                     return TokenKind::Literal(LiteralKind::Int {
  %                         base,
  %                         empty_int: true,
  %                     });
  %                 }
  %             }
  %             'h' | 'H' => {
  %                 self.eat();
  %                 base = Base::Hexadecimal;
  %                 if !self.eat_hexa_digits() {
  %                     return TokenKind::Literal(LiteralKind::Int {
  %                         base,
  %                         empty_int: true,
  %                     });
  %                 }
  %             }

  %             // Not a base prefix, eats all digits
  %             '0'..='9' | '_' => {
  %                 self.eat_decimal_digits();
  %             }

  %             '.' | 'e' | 'E' => {}

  %             // Just 0.
  %             _ => {
  %                 return TokenKind::Literal(LiteralKind::Int {
  %                     base,
  %                     empty_int: false,
  %                 });
  %             }
  %         }
  %     } else {
  %         self.eat_decimal_digits();
  %     }

  %     // Only Decimal base here, and the part before `.` or `e|E` has been eaten.
  %     match self.first() {
  %         // After '.' cannot be id_start because we might add method for primary type in the
  %         // future.
  %         '.' if !is_id_start(self.second()) => {
  %             self.eat();

  %             // If there is something after '.', it has to be a number. Else we will stop
  %             // consumming (e.g. '3.').
  %             if self.first().is_ascii_digit() {
  %                 self.eat_decimal_digits();
  %                 match self.first() {
  %                     'e' | 'E' => {
  %                         self.eat();
  %                         return TokenKind::Literal(LiteralKind::Float {
  %                             base,
  %                             empty_exponent: !self.eat_exponent(),
  %                         });
  %                     }
  %                     _ => (),
  %                 }
  %             }

  %             TokenKind::Literal(LiteralKind::Float {
  %                 base,
  %                 empty_exponent: false,
  %             })
  %         }
  %         'e' | 'E' => {
  %             self.eat();
  %             return TokenKind::Literal(LiteralKind::Float {
  %                 base,
  %                 empty_exponent: !self.eat_exponent(),
  %             });
  %         }
  %         // Just a normal integer number.
  %         _ => {
  %             return TokenKind::Literal(LiteralKind::Int {
  %                 base,
  %                 empty_int: false,
  %             })
  %         }
  %     }
  %   }
  % \end{lstlisting}
  \item Xử lí loại từ tố tên thô và chuỗi thô: ký tự đang được đọc là 'r', ta sẽ xác định 2 ký tự tiếp theo ngay sau nó. Nếu ký tự tiếp theo là '\#' và sau đó là ký tự bắt đầu tên hợp lệ thì xác định loại từ tố tên thô bằng hàm \textit{raw\_identifier}; Nếu ký tự tiếp theo là '\#' hoặc '"' thì xác định loại từ tố chuỗi thô bằng hàm \textit{raw\_double\_quote\_string}; Trường hợp còn lại thì ta sẽ xác định loại từ tố tên bằng hàm \textit{identifier.}
  % \begin{lstlisting}[]
  %   fn raw_double_quote_string(&mut self) -> Result<u8, RawStrError> {
  %     debug_assert!(self.prev() == 'r' && matches!(self.first(), '#' | '"'));

  %     let start_pos = self.bytes_eaten();
  %     let mut start_hashes = 0;

  %     while self.first() == '#' {
  %         self.eat();
  %         start_hashes += 1;
  %     }

  %     match self.eat() {
  %         Some('"') => {}
  %         c => {
  %             let bad_char = c.unwrap_or(EOF_CHAR);
  %             return Err(RawStrError::InvalidStarter { bad_char });
  %         }
  %     }

  %     let mut possible_terminator_offset: Option<u32> = None;
  %     let mut max_end_hashes: u32 = 0;
  %     let mut maybe_end_hashes: u32;

  %     loop {
  %         self.eat_while(|ch| ch != '"');
  %         if self.is_eof() {
  %             return Err(RawStrError::NoTerminator {
  %                 expected: start_hashes,
  %                 found: max_end_hashes,
  %                 possible_terminator_offset,
  %             });
  %         }

  %         self.eat();
  %         maybe_end_hashes = 0;
  %         while self.first() == '#' && maybe_end_hashes < start_hashes {
  %             self.eat();
  %             maybe_end_hashes += 1;
  %         }

  %         if maybe_end_hashes == start_hashes {
  %             if maybe_end_hashes > 255 {
  %                 return Err(RawStrError::TooManyHashes {
  %                     found: maybe_end_hashes,
  %                 });
  %             }

  %             return Ok(start_hashes as u8);
  %         }

  %         // end < start
  %         if maybe_end_hashes > max_end_hashes {
  %             max_end_hashes = maybe_end_hashes;
  %             possible_terminator_offset =
  %                 Some(self.bytes_eaten() - start_pos + 1 - max_end_hashes);
  %         }
  %     }
  %   }
  % \end{lstlisting}
  \item Xử lí ký tự: ký tự đang được đọc là dấu nháy đơn (') thì ta sẽ xác định loại từ tố ký tự bằng hàm \textit{single\_quote\_string}. Hàm này sẽ xử lí toàn bộ chuỗi kí tự năm giữa cặp nháy đơn (') do đó hàm vẫn mang tên \\\textit{single\_quote\_string} mà không phải là \textit{single\_quote\_char}, nếu chuỗi này nhiều hơn 1 ký tự, chương trình sẽ báo lỗi ở giai đoạn sau.
  % \begin{lstlisting}[]
  %   fn single_quote_string(&mut self) -> TokenKind {
  %     debug_assert!(self.prev() == '\'');

  %     // If it only contains 1 symbol.
  %     if self.first() != '\\' && self.second() == '\'' {
  %         self.eat();
  %         self.eat();
  %         return TokenKind::Literal(LiteralKind::Char { terminated: true });
  %     }

  %     // This can contains more than 1 symbol.
  %     let mut terminated = false;
  %     while !self.is_eof() {
  %         match self.first() {
  %             '\'' => {
  %                 terminated = true;
  %                 self.eat();
  %                 break;
  %             }
  %             // Probably beginning of the comment, which we don't want to include
  %             // to the error report.
  %             '/' => break,
  %             // Newline without following '\'' means unclosed quote, stop parsing.
  %             '\n' if self.second() != '\'' => break,
  %             // Eats twice because \ will take the character after it.
  %             '\\' => {
  %                 self.eat();
  %                 self.eat();
  %             }
  %             _ => {
  %                 self.eat();
  %             }
  %         }
  %     }

  %     TokenKind::Literal(LiteralKind::Char { terminated })
  %   }
  % \end{lstlisting}
  \item Xử lí chuỗi: ký tự đang được đọc là dấu nháy kép (") thì ta sẽ xác định loại từ tố chuỗi bằng hàm \textit{double\_quote\_string}. 
  % \begin{lstlisting}[]
  %   fn double_quote_string(&mut self) -> TokenKind {
  %     debug_assert!(self.prev() == '"');

  %     let mut terminated = false;
  %     while !self.is_eof() {
  %         match self.first() {
  %             // This will eat the character after it.
  %             '\\' => {
  %                 self.eat();
  %                 self.eat();
  %             }
  %             '"' => {
  %                 self.eat();
  %                 terminated = true;
  %                 break;
  %             }
  %             _ => {
  %                 self.eat();
  %             }
  %         }
  %     }

  %     TokenKind::Literal(LiteralKind::Str { terminated })
  %   }
  % \end{lstlisting}
  \item Nếu ký tự đang đọc là 1 ký tự bất kì nào khác mà là ký tự bắt đầu tên hợp lệ thì ta sẽ xác định loại từ tố tên bằng hàm \textit{identifier}. 
  % \begin{lstlisting}[]
  %   fn identifier(&mut self) -> TokenKind {
  %     // The first symbol is already eaten and checked so this must be true.
  %     debug_assert!(is_id_start(self.prev()));

  %     self.eat_while(|ch| is_id_continue(ch));

  %     TokenKind::Ident
  %   }
  % \end{lstlisting}
  \item Nếu ký tự đang đọc không thỏa mãn bất kì trường hợp nào trên thì sẽ là loại từ tố không xác định.
\end{itemize}


\textbf{Giai đoạn 2.} \textit{Phân tích từ tố thứ cấp}

Từ tố thứ cấp bao gồm các thuộc tính là loại từ tố và vị trí của từ tố:
\begin{lstlisting}
  pub struct Token {
    pub kind: TokenKind,
    pub span: Span,
  }
\end{lstlisting}

Vị trí của từ tố thứ cấp sẽ bao gồm 2 thuộc tính là \textit{offset} cho biết vị trí bắt đầu của token trong chuỗi đầu vào, và thuộc tính \textit{length} cho biết chiều dài của token trong chuỗi đầu vào:
\begin{lstlisting}
  pub struct Span {
    /// The start of the span.
    pub offset: BytePos,
    /// The total length of the span
    pub length: usize,
  }
\end{lstlisting}

Ở giai đoạn này các từ tố sơ cấp sẽ được "\textit{nấu}" lên tạo thành các từ tố thứ cấp. Các loại từ tố thứ cấp được thể hiện như sau:
\begin{lstlisting}
  pub enum TokenKind {
    /* Expression-operator symbols. */
    /// `=`
    Eq,
    /// `<`
    Lt,
    /// `<=`
    Le,
    /// `==`
    EqEq,
    /// `!=`
    Ne,
    /// `>=`
    Ge,
    /// `>`
    Gt,
    /// `&&`
    AndAnd,
    /// `||`
    OrOr,
    /// `!`
    Not,
    /// `~`
    Tilde,
    BinOp(BinOpToken),
    BinOpEq(BinOpToken),

    /* Structural symbols */
    /// `.`
    Dot,
    /// `,`
    Comma,
    /// `;`
    Semicolon,
    /// `:`
    Colon,
    /// `?`
    Question,
    /// An opening delimiter (e.g., `{`).
    OpenDelim(Delimiter),
    /// A closing delimiter (e.g., `}`).
    CloseDelim(Delimiter),

    /* Literals */
    Literal(Lit),

    Ident(Symbol, IdentIsRaw),

    /// A doc comment token.
    /// `Symbol` is the data of doc's comment excluding its "quotes" (`///`, `/**`, etc)
    DocComment(CommentKind, Option<DocStyle>, Symbol),

    /// End Of File.
    Eof,
  }
\end{lstlisting} 

Ngoài các loại từ tố đã được chú thích cụ thể ở trên, có 1 số loại từ tố cần được thể hiện thông qua 1 hoặc nhiều giá trị khác, cụ thể:
\begin{itemize}
  \item \textit{BinOp} là loại từ tố bao gồm các ký tự là phép toán (cộng, trừ, nhân, chia, chia lấy dư, and, or, xor, dịch trái, dịch phải) được thể hiện qua enum \textit{BinOpToken}:
  \begin{lstlisting}
  pub enum BinOpToken {
    Plus,
    Minus,
    Star,
    Slash,
    Percent,
    Caret,
    And,
    Or,
    Shl,
    Shr,
  }
  \end{lstlisting}
  \item \textit{OpenDelim \emph{và} CloseDelim} là 2 loại từ tố tương ứng thể hiện kiểu mở và đóng ngoặc. Nó được thể hiện qua enum \textit{Delimiter}:
  \begin{lstlisting}
    pub enum Delimiter {
      /// `( ... )`
      Parenthesis,
      /// `{ ... }`
      Brace,
      /// `[ ... ]`
      Bracket,
    }        
  \end{lstlisting}
  \item \textit{Literal} là loại từ tố chuỗi ký tự được thể hiện qua cấu trúc \textit{Lit} với 2 thuộc tính là \textit{kind} và \textit{symbol}. 
  \\Thuộc tính \textit{kind} có kiểu \textit{LitKind} được thể hiện qua enum \textit{LitKind}: 
  \begin{lstlisting}
    pub enum LitKind {
      Bool,
      Char,
      Int,
      Float,
      Str,
      RawStr(u8), // raw string delimited by `n` hash symbols
  
      Err,
    }
  \end{lstlisting}
  Thuộc tính \textit{symbol} có kiểu \textit{Symbol} là giá trị được số hóa được giá trị thực của chuỗi:
  \begin{lstlisting}
    pub struct Symbol(u32);
  \end{lstlisting}


  \item \textit{Ident} là từ tố tên, được thể hiện bởi 2 giá trị là \textit{Symbol} lưu giá trị của tên dưới dạng số 32bit và \textit{IdentIsRaw} để xác định xem đây có phải là tên thô hay không:
  \begin{lstlisting}
    pub enum IdentIsRaw {
      Yes,
      No,
    }
  \end{lstlisting}
  
  \item \textit{DocComment} là từ tố chú thích tài liệu:
  

        Từ tố này thể hiện qua 3 giá trị. 
        \\Thứ nhất là \textit{CommentKind} cho biết loại chú thích là chú thích dòng hay đoạn:
  \begin{lstlisting}
  pub enum CommentKind {
    Line,
    Block,
  }
  \end{lstlisting}
        Thứ hai là \textit{Option<DocStyle>} cho biết kiểu chú thích là bên trong hay bên ngoài khối lệnh:
  \begin{lstlisting}
  pub enum DocStyle {
    Inner,
    Outer,
  }
  \end{lstlisting}
        Thứ ba là \textit{Symbol} lưu giá trị của chú thích dưới dạng số.
\end{itemize}

Hàm \textit{next\_token} được sử dụng để đọc từ tố sơ cấp tiếp theo trong chuỗi ký tự đầu vào, sau đó "\textit{nấu}" chúng thành từ tố thứ cấp như sau:

\begin{itemize}
  \item Các khoảng trắng sẽ được bỏ qua.
  \begin{lstlisting}
    fn next_token(&mut self) -> Token {
      // Skip trivial (whitespaces and comments) tokens.
          ...
  
          let kind = match token.kind {
              lexer::TokenKind::Whitespace => {
                  continue;
              }
              
              ...
          };
  
          ...
    }
  \end{lstlisting}
  \item Từ tố thứ cấp chú thích tài liệu dòng và đoạn: Nếu từ tố đang được đọc là từ tố sơ cấp chú thích dòng hoặc đoạn thì ta thực hiện loại bỏ các chú thích thông thường, sau đó chuyển phần chú thích tài liệu còn lại thành từ tố thứ cấp chú thích tài liệu dòng hoặc đoạn tương ứng.
  \begin{lstlisting}
    fn next_token(&mut self) -> Token {
      // Skip trivial (whitespaces and comments) tokens.
          ...
  
          let kind = match token.kind {
              ...

              lexer::TokenKind::LineComment { doc_style } => {
                  // Skip normal comment
                  let Some(doc_style) = doc_style else {
                      continue;
                  };
  
                  let content_start = start_pos + 3; // skip "quotes" (//! or //@)
                  let content_end = self.pos;
                  let content = self.str_from_to(content_start, content_end);
                  self.cook_doc_comment(content, CommentKind::Line, doc_style)
              }
              lexer::TokenKind::BlockComment {
                  doc_style,
                  terminated,
              } => {
                  if !terminated {
                      self.report_unterminated_block_comment(start_pos, doc_style);
                  }
  
                  // Skip normal comment
                  let Some(doc_style) = doc_style else {
                      continue;
                  };
  
                  let content_start = start_pos + 3; // skip "quotes" (/*! or /*@)
                  let content_end = self.pos - if terminated { 2 } else { 0 };
                  let content = self.str_from_to(content_start, content_end);
                  self.cook_doc_comment(content, CommentKind::Block, doc_style)
              }
              
              ...
          };
  
          ...
    }
  \end{lstlisting}
  \item Từ tố thứ cấp tên: Nếu từ tố đang được đọc là từ tố sơ cấp tên thì nó sẽ được chuyển thành từ tố thứ cấp tên thông qua hàm \textit{cook\_ident}; Nếu từ tố đang được đọc là từ tố sơ cấp tên thô thì nó sẽ được chuyển thành từ tố thứ cấp tên thông qua hàm \textit{cook\_raw\_ident}.
  \begin{lstlisting}
    fn next_token(&mut self) -> Token {
      // Skip trivial (whitespaces and comments) tokens.
          ...
  
          let kind = match token.kind {
              ...    
  
              lexer::TokenKind::Ident => {
                  let content = self.str_from_to(start_pos, self.pos);
                  self.cook_ident(content)
              }
              lexer::TokenKind::RawIdent => {
                  let content = self.str_from_to(start_pos + 2, self.pos); // skip r#
                  self.cook_raw_ident(content)
              }
              
              ...
          };
  
          ...
    }
  \end{lstlisting}
  \item Từ tố chuỗi ký tự: Nếu từ tố đang được đọc là từ tố sơ cấp chuỗi kí tự thì nó sẽ được chuyển thành từ tố thứ cấp chuỗi kí tự với kiểu tương ứng thông qua hàm \textit{cook\_literal}.
  \begin{lstlisting}
    fn next_token(&mut self) -> Token {
      // Skip trivial (whitespaces and comments) tokens.
          ...
  
          let kind = match token.kind {
              ...    
  
              lexer::TokenKind::Literal(kind) => self.cook_literal(start_pos, self.pos, kind),
  
              ...
          };
  
          ...
    }
  \end{lstlisting}
  \item Các ký tự đơn sẽ được chuyển từ từ tố sơ cấp thành từ tố thứ cấp tương ứng.
  \begin{lstlisting}
    fn next_token(&mut self) -> Token {
      // Skip trivial (whitespaces and comments) tokens.
          ...
  
          let kind = match token.kind {
              ...    
  
              lexer::TokenKind::Eq => TokenKind::Eq,
              lexer::TokenKind::Lt => TokenKind::Lt,
              lexer::TokenKind::Gt => TokenKind::Gt,
              lexer::TokenKind::Bang => TokenKind::Not,
              lexer::TokenKind::Tilde => TokenKind::Tilde,
              lexer::TokenKind::Plus => TokenKind::BinOp(BinOpToken::Plus),
              lexer::TokenKind::Minus => TokenKind::BinOp(BinOpToken::Minus),
              lexer::TokenKind::Star => TokenKind::BinOp(BinOpToken::Star),
              lexer::TokenKind::Slash => TokenKind::BinOp(BinOpToken::Slash),
              lexer::TokenKind::Percent => TokenKind::BinOp(BinOpToken::Percent),
              lexer::TokenKind::Caret => TokenKind::BinOp(BinOpToken::Caret),
              lexer::TokenKind::And => TokenKind::BinOp(BinOpToken::And),
              lexer::TokenKind::Or => TokenKind::BinOp(BinOpToken::Or),
              lexer::TokenKind::Dot => TokenKind::Dot,
              lexer::TokenKind::Comma => TokenKind::Comma,
              lexer::TokenKind::Semicolon => TokenKind::Semicolon,
              lexer::TokenKind::Colon => TokenKind::Colon,
              lexer::TokenKind::Question => TokenKind::Question,
              lexer::TokenKind::OpenParen => TokenKind::OpenDelim(Delimiter::Parenthesis),
              lexer::TokenKind::CloseParen => TokenKind::CloseDelim(Delimiter::Parenthesis),
              lexer::TokenKind::OpenBrace => TokenKind::OpenDelim(Delimiter::Brace),
              lexer::TokenKind::CloseBrace => TokenKind::CloseDelim(Delimiter::Brace),
              lexer::TokenKind::OpenBracket => TokenKind::OpenDelim(Delimiter::Bracket),
              lexer::TokenKind::CloseBracket => TokenKind::CloseDelim(Delimiter::Bracket),
  
              ...
          };
  
          ...
    }
  \end{lstlisting}
  \item Từ tố sơ cấp không xác định sẽ được bỏ qua và cảnh báo.
  \begin{lstlisting}
    fn next_token(&mut self) -> Token {
      // Skip trivial (whitespaces and comments) tokens.
          ...
  
          let kind = match token.kind {
              ...    
  
              lexer::TokenKind::Unknown => {
                  self.report_unknown_symbol(start_pos, self.pos);
                  continue;
              }
  
              ...
          };
  
          ...
    }
  \end{lstlisting}
  \item Từ tố sơ cấp kết thúc đầu vào cũng được chuyển thành từ tố thứ cấp tương ứng.
  \begin{lstlisting}
    fn next_token(&mut self) -> Token {
      // Skip trivial (whitespaces and comments) tokens.
          ...
  
          let kind = match token.kind {
              ...    
  
              lexer::TokenKind::Eof => TokenKind::Eof,
          };
  
          ...
    }
  \end{lstlisting}
\end{itemize}

\textbf{Giai đoạn 3.} \textit{Phân tích cây từ tố}

Cây từ tố là cấp độ từ tố phức tạp hơn so với 2 cấp độ trước. 1 cây từ tố có thể là 1 từ tố đơn (lá), hoặc là 1 nhóm các cây từ tố con được đặt trong cặp đóng mở ngoặc (1 cây từ tố con).

\begin{lstlisting}
  pub enum TokenTree {
    /// A single token. Should never be `OpenDelim` or `CloseDelim`, because
    /// delimiters are implicitly represented by `Delimited`.
    Token(Token, Spacing),
    // A delimited sequence of token trees.
    Delimited(DelimSpan, Delimiter, TokenStream),
  }
\end{lstlisting}

Cụ thể:
\begin{itemize}
  \item Từ tố đơn (Token). Mỗi cây từ tố thuộc loại này bao gồm 2 giá trị: thứ nhất là giá trị thuộc \textit{Token} (từ tố thứ cấp được đoán nhận ở giai đoạn 2), thứ hai là giá trị \textit{Spacing}. \textit{Spacing} có 2 loại là \textit{Alone \emph{và} Joint}. \textit{Alone} được sử dụng khi theo sau từ tố là 1 từ tố khoảng trắng, từ tố này không thể kết hợp với từ tố khác. \textit{Joint} được sử dụng khi theo sau từ tố là 1 từ tố dấu câu cho phép chúng kết hợp đựợc với nhau (ví dụ '<' và'=' có thể kết hợp thành "<=", \dots).
  \begin{lstlisting}
  pub enum Spacing {
    /// The token cannot join with the following token to form a compound
    /// token.
    ///
    /// In token streams parsed from source code, the compiler will use `Alone`
    /// for any token immediately followed by whitespace, a non-doc comment, an identifier,
    /// literal, delimiter, doc comment or EOF.
    Alone,

    /// The token can join with the following token to form a compound token.
    ///
    /// In token streams parsed from source code, the compiler will use `Joint`
    /// for any token immediately followed by punctuation (as determined by
    /// `Token::is_punct`).
    Joint,
  }
  \end{lstlisting}
  \item Nhóm các cây từ tố con được đặt trong cặp ngoặc (Delimited). Mỗi cây từ tố thuộc loại này bao gồm 3 giá trị:
  \begin{itemize}
    \item DelimSpan cho biết của vị trí mở ngoặc và đóng ngoặc
          \begin{lstlisting}
            pub struct DelimSpan {
              pub open: Span,
              pub close: Span,
            }
          \end{lstlisting}
    \item Delimiter cho biết kiểu của ngoặc (ngoặc ngọn, ngoặc tròn, ngoặc vuông)
          \begin{lstlisting}
            pub enum Delimiter {
              /// `( ... )`
              Parenthesis,
              /// `{ ... }`
              Brace,
              /// `[ ... ]`
              Bracket,
            }
          \end{lstlisting}
    \item TokenStream con trỏ trỏ đến 1 danh sách các cây từ tố con
          \begin{lstlisting}
            pub type TokenStream = Rc<Vec<TokenTree>>;
          \end{lstlisting}
  \end{itemize}
\end{itemize}

Hàm \textit{lex\_token\_trees} sẽ đọc các từ tố thứ cấp nhận được từ giai đoạn 2 và chuyển chúng thành cây từ tố như sau:

\begin{itemize}
  \item Nếu từ tố đang được đọc là dấu mở ngoặc, ta sẽ bắt đầu đoán nhận 1 cây từ tố loại \textit{Delimited} thông qua hàm \textit{lex\_token\_tree\_open\_delim}:
  \begin{lstlisting}
    fn lex_token_trees(&mut self, is_delimited: bool) -> (TokenStream, bool) {
      ...
  
          match self.token.kind {
              TokenKind::OpenDelim(delim) => match self.lex_token_tree_open_delim(delim) {
                  Some(val) => buf.push(val),
                  None => return (TokenStream::new(buf), false),
              },
              
              ...
          }
  
    }
  \end{lstlisting}
  \item Nếu từ tố đang được đọc là dấu đóng ngoặc, sẽ trả về cây từ tố đã đọc được:
  \begin{lstlisting}
    fn lex_token_trees(&mut self, is_delimited: bool) -> (TokenStream, bool) {
      ...
  
          match self.token.kind {
              ...
              
              TokenKind::CloseDelim(_delim) => {
                  let mut no_err = true;
                  if !is_delimited {
                      no_err = false;
                      self.report_close_delim_error();
                  }
                  return (TokenStream::new(buf), no_err);
              }
              
              ...
          }
  
    }
  \end{lstlisting}
  \item Nếu từ tố đang được đọc là Từ tố kết thúc đầu vào, sẽ trả về cây từ tố đã đọc được, đồng thời sẽ đưa ra cảnh báo nếu cây từ tố này không được đóng đúng cách:
  \begin{lstlisting}
    fn lex_token_trees(&mut self, is_delimited: bool) -> (TokenStream, bool) {
      ...
  
          match self.token.kind {
              ...

              TokenKind::Eof => {
                  let mut no_err = true;
                  if is_delimited {
                      no_err = false;
                      self.report_eof_error();
                  }
                  return (TokenStream::new(buf), no_err);
              }
              
              ...
          }
  
    }
  \end{lstlisting}
  \item Nếu từ tố đang được đọc là từ tố thứ cấp bình thường, sẽ thêm cây từ tố loại \textit{Token} vào danh sách cây từ tố hiện tại:
  \begin{lstlisting}
    fn lex_token_trees(&mut self, is_delimited: bool) -> (TokenStream, bool) {
      ...
  
          match self.token.kind {
              ...

              _ => {
                  // Get the next normal token.
                  // We will have the previous token, so we can try to glue.
                  let (this_tok, this_spacing) = self.eat(true);
                  buf.push(TokenTree::Token(this_tok, this_spacing));
              }
          }
  
    }
  \end{lstlisting}
\end{itemize}